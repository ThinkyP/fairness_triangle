{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f336f286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import sys\n",
    "sys.path.insert(1, '/home/ptr@itd.local/code/fairness_triangle/tools')  # Update this path as needed\n",
    "from preprocessing import *\n",
    "from sklearn.utils import resample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c4cea88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_346767/3983548663.py:2: DtypeWarning: Columns (22,23,24,26,27,28,29,30,31,32,33,38,43,44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  sample_df = pd.read_csv(\"../datasets/2024_public_lar.csv\", skiprows=lambda i: i > 0 and random.random() > 0.05)\n"
     ]
    }
   ],
   "source": [
    "random.seed(42) # For reproducibility\n",
    "sample_df = pd.read_csv(\"../datasets/2024_public_lar.csv\", skiprows=lambda i: i > 0 and random.random() > 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f5b68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (611273, 99)\n",
      "New shape after drop: (611273, 64)\n"
     ]
    }
   ],
   "source": [
    "# Find columns with >35% missing values\n",
    "missing_ratio = sample_df.isnull().mean()\n",
    "cols_to_drop = missing_ratio[missing_ratio > 0.35].index.tolist()\n",
    "cols_to_drop = cols_to_drop + ['lei'] + ['applicant_age_above_62']\n",
    "#print(\"Columns with >35% missing values:\")\n",
    "#print(cols_to_drop)\n",
    "\n",
    "# Drop them from the DataFrame\n",
    "sample_df_clean = sample_df.drop(columns=cols_to_drop)\n",
    "print(f\"Original shape: {sample_df.shape}\")\n",
    "print(f\"New shape after drop: {sample_df_clean.shape}\")\n",
    "\n",
    "must_have_val = [\n",
    "    'activity_year',\n",
    "    'co_applicant_ethnicity_1',\n",
    "    'co_applicant_race_1',\n",
    "    'state_code',\n",
    "    'county_code',\n",
    "    'census_tract',\n",
    "    'loan_amount',\n",
    "    'property_value',\n",
    "    'income',\n",
    "    'debt_to_income_ratio',\n",
    "    'applicant_credit_score_type',\n",
    "    'action_taken',\n",
    "    'aus_1',\n",
    "    'applicant_race_1',\n",
    "    'applicant_ethnicity_1',\n",
    "    'applicant_sex'\n",
    "]\n",
    "\n",
    "\n",
    "sample_df_clean = sample_df_clean.dropna(subset=must_have_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "71e4738a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Y bar binary (m/w)\n",
    "sample_df_clean['applicant_sex'].unique()\n",
    "sample_df_clean = sample_df_clean[sample_df_clean['applicant_sex'].isin([1, 2])]\n",
    "sample_df_clean['applicant_sex'] = sample_df_clean['applicant_sex'].replace({1: 0, 2: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "514d22a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.57020663956639\n"
     ]
    }
   ],
   "source": [
    "#Make Y binary (loan originated/not originated)\n",
    "sample_df_clean['action_taken'] = sample_df_clean['action_taken'].apply(lambda x: 1 if x == 1 else 0)\n",
    "print((sample_df_clean['action_taken'] == 1).mean() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fafda38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "df_1 = sample_df_clean[sample_df_clean['action_taken'] == 1]\n",
    "df_0 = sample_df_clean[sample_df_clean['action_taken'] == 0]\n",
    "\n",
    "# Downsample majority class to match minority class size\n",
    "df_1_balanced = resample(df_1, replace=False, n_samples=len(df_0), random_state=42)\n",
    "\n",
    "# Combine and shuffle\n",
    "sample_df_clean = pd.concat([df_1_balanced, df_0]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d907d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "df_1 = sample_df_clean[sample_df_clean['applicant_sex'] == 1]\n",
    "df_0 = sample_df_clean[sample_df_clean['applicant_sex'] == 0]\n",
    "\n",
    "# Downsample majority class to match minority class size\n",
    "df_0_balanced = resample(df_0, replace=False, n_samples=len(df_1), random_state=42)\n",
    "\n",
    "# Combine and shuffle\n",
    "sample_df_clean = pd.concat([df_0_balanced, df_1]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e2575a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.00%\n",
      "49.57%\n"
     ]
    }
   ],
   "source": [
    "percentage_ones = (sample_df_clean['applicant_sex'] == 1).mean() * 100\n",
    "print(f\"{percentage_ones:.2f}%\")\n",
    "percentage_ones = (sample_df_clean['action_taken'] == 1).mean() * 100\n",
    "print(f\"{percentage_ones:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74360c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_ones = (sample_df_clean['action_taken'] == 1).mean() * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "318449ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert loan_term to int and remove NaN\n",
    "sample_df_clean['loan_term'] = pd.to_numeric(sample_df_clean['loan_term'], errors='coerce')\n",
    "sample_df_clean = sample_df_clean.dropna(subset=['loan_term'])\n",
    "sample_df_clean['loan_term'] = sample_df_clean['loan_term'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86c1c93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert loacombined_loan_to_value_ration_term to float and remove NaN\n",
    "sample_df_clean['combined_loan_to_value_ratio'] = pd.to_numeric(sample_df_clean['combined_loan_to_value_ratio'], errors='coerce')\n",
    "sample_df_clean = sample_df_clean.dropna(subset=['combined_loan_to_value_ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c177dab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert interest_rate to float and remove NaN\n",
    "sample_df_clean['interest_rate'] = pd.to_numeric(sample_df_clean['interest_rate'], errors='coerce')\n",
    "sample_df_clean = sample_df_clean.dropna(subset=['interest_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04cefa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert loan_term to int and remove NaN\n",
    "sample_df_clean['property_value'] = pd.to_numeric(sample_df_clean['property_value'], errors='coerce')\n",
    "sample_df_clean = sample_df_clean.dropna(subset=['property_value'])\n",
    "sample_df_clean['property_value'] = sample_df_clean['property_value'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "315f07b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.57020663956639\n"
     ]
    }
   ],
   "source": [
    "print((sample_df_clean['action_taken'] == 1).mean() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a3c6335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding total_units ordinally and removing Nan\n",
    "sample_df_clean['total_units'] = sample_df_clean['total_units'].astype(str).str.strip()\n",
    "\n",
    "category_order = [['1', '2', '3', '4', '5-24', '25-49', '50-99', '>149']]\n",
    "\n",
    "\n",
    "encoder = OrdinalEncoder(categories=category_order)\n",
    "sample_df_clean['total_units'] = encoder.fit_transform(\n",
    "    sample_df_clean[['total_units']]\n",
    ").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb1f515c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding applicant_age and co_applicant age and removing Nan\n",
    "sample_df_clean['applicant_age'] = sample_df_clean['applicant_age'].replace('8888', np.nan)\n",
    "sample_df_clean = sample_df_clean.dropna(subset=['applicant_age'])\n",
    "age_order = [['<25', '25-34', '35-44', '45-54', '55-64', '65-74', '>74']]\n",
    "encoder = OrdinalEncoder(categories=age_order)\n",
    "sample_df_clean['applicant_age'] = encoder.fit_transform(sample_df_clean[['applicant_age']]).astype(int)\n",
    "\n",
    "\n",
    "sample_df_clean['co_applicant_age'] = sample_df_clean['co_applicant_age'].replace(['8888', '9999'], np.nan)\n",
    "sample_df_clean = sample_df_clean.dropna(subset=['co_applicant_age'])\n",
    "age_order = [['<25', '25-34', '35-44', '45-54', '55-64', '65-74', '>74']]\n",
    "encoder = OrdinalEncoder(categories=age_order)\n",
    "sample_df_clean['co_applicant_age'] = encoder.fit_transform(sample_df_clean[['co_applicant_age']]).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d89a2f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.57020663956639\n"
     ]
    }
   ],
   "source": [
    "print((sample_df_clean['action_taken'] == 1).mean() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0dfe6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding state_code\n",
    "sample_df_clean['state_code'] = sample_df_clean['state_code'].astype(str).str.strip()\n",
    "\n",
    "# One-hot encode\n",
    "state_dummies = pd.get_dummies(sample_df_clean['state_code'], prefix='state_code', drop_first=True)\n",
    "sample_df_clean = pd.concat([sample_df_clean.drop(columns=['state_code']), state_dummies], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fe94bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42 25 20 55 48 33 46 44 41 36 40 49 43 45 38 47 37 39 60]\n"
     ]
    }
   ],
   "source": [
    "#Encode debt_to_income_ratio\n",
    "sample_df_clean['debt_to_income_ratio'] = sample_df_clean['debt_to_income_ratio'].apply(parse_dti)\n",
    "\n",
    "# Convert to integer if no NaNs remain, otherwise keep float\n",
    "if sample_df_clean['debt_to_income_ratio'].isna().sum() == 0:\n",
    "    sample_df_clean['debt_to_income_ratio'] = sample_df_clean['debt_to_income_ratio'].astype(int)\n",
    "\n",
    "print(sample_df_clean['debt_to_income_ratio'].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "087d26c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df_clean['derived_race'] = sample_df_clean['derived_race'].astype(str).str.strip()\n",
    "race_dummies = pd.get_dummies(sample_df_clean['derived_race'], prefix='derived_race', drop_first=True)\n",
    "sample_df_clean = pd.concat([sample_df_clean.drop(columns=['derived_race']), race_dummies], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a466cb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df_clean['derived_loan_product_type'] = sample_df_clean['derived_loan_product_type'].astype(str).str.strip()\n",
    "loan_type_dummies = pd.get_dummies(sample_df_clean['derived_loan_product_type'], prefix='loan_product_type', drop_first=True)\n",
    "sample_df_clean = pd.concat([sample_df_clean.drop(columns=['derived_loan_product_type']), loan_type_dummies], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6715c199",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df_clean['derived_ethnicity'] = sample_df_clean['derived_ethnicity'].astype(str).str.strip()\n",
    "ethnicity_dummies = pd.get_dummies(sample_df_clean['derived_ethnicity'], prefix='derived_ethnicity', drop_first=True)\n",
    "sample_df_clean = pd.concat([sample_df_clean.drop(columns=['derived_ethnicity']), ethnicity_dummies], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac6b3f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df_clean['derived_sex'] = sample_df_clean['derived_sex'].astype(str).str.strip()\n",
    "sex_dummies = pd.get_dummies(sample_df_clean['derived_sex'], prefix='derived_sex', drop_first=True)\n",
    "sample_df_clean = pd.concat([sample_df_clean.drop(columns=['derived_sex']), sex_dummies], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb33202e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df_clean['derived_dwelling_category'] = sample_df_clean['derived_dwelling_category'].astype(str).str.strip()\n",
    "dwelling_dummies = pd.get_dummies(sample_df_clean['derived_dwelling_category'], prefix='dwelling_category', drop_first=True)\n",
    "sample_df_clean = pd.concat([sample_df_clean.drop(columns=['derived_dwelling_category']), dwelling_dummies], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f04640c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df_clean = sample_df_clean.dropna(subset=['conforming_loan_limit'])\n",
    "sample_df_clean['conforming_loan_limit'] = sample_df_clean['conforming_loan_limit'].map({'C': 1,'NC': 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8566f57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = sample_df_clean['action_taken'].astype(int)\n",
    "Y_sen = sample_df_clean['applicant_sex'].astype(int)\n",
    "X =sample_df_clean.drop(columns=[\"action_taken\", \"applicant_sex\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4b576b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1\n",
       "1         1\n",
       "2         1\n",
       "3         1\n",
       "4         0\n",
       "         ..\n",
       "141691    1\n",
       "141692    1\n",
       "141693    0\n",
       "141694    0\n",
       "141695    0\n",
       "Name: action_taken, Length: 141696, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df_clean['action_taken']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cbe6b957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.57020663956639\n"
     ]
    }
   ],
   "source": [
    "print((sample_df_clean['action_taken'] == 1).mean() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a600c560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_train 49.57% are 1\n",
      "Y_test: 50.00% are 1\n"
     ]
    }
   ],
   "source": [
    "pct_Y = (Y == 1).mean() * 100\n",
    "pct_Y_sen_train = (Y_sen == 1).mean() * 100\n",
    "\n",
    "print(f\"Y_train {pct_Y:.2f}% are 1\")\n",
    "print(f\"Y_test: {pct_Y_sen_train:.2f}% are 1\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
